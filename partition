from itertools import combinations

def generateCandidateItemsets(level_k, level_frequent_itemsets):
	n_frequent_itemsets = len(level_frequent_itemsets)
	candidate_frequent_itemsets = []
	for i in range(n_frequent_itemsets):
		j = i+1
		while (j<n_frequent_itemsets) and (level_frequent_itemsets[i][:level_k-1] == level_frequent_itemsets[j][:level_k-1]):
			
			candidate_itemset = level_frequent_itemsets[i][:level_k-1] + [level_frequent_itemsets[i][level_k-1]] + [level_frequent_itemsets[j][level_k-1]]
			candidate_itemset_pass = False

			if level_k == 1:
				candidate_itemset_pass = True
				
			elif (level_k == 2) and (candidate_itemset[-2:] in level_frequent_itemsets):
				candidate_itemset_pass = True

			elif all((list(_)+candidate_itemset[-2:]) in level_frequent_itemsets for _ in combinations(candidate_itemset[:-2], level_k-2)):
				candidate_itemset_pass = True
				
			if candidate_itemset_pass:
				candidate_frequent_itemsets.append(candidate_itemset)

			j += 1

	return candidate_frequent_itemsets


def aprioriAlgorithm(transactions, min_support_count):
	items = set()
	for transaction in transactions:
		items.update(transaction)
	items = sorted(list(items))
	frequent_itemsets = []

	level_k = 1 

	level_frequent_itemsets = [] 
	candidate_frequent_itemsets = [[item] for item in items] 
	while candidate_frequent_itemsets:
		candidate_freq_itemsets_cnts = [0]*len(candidate_frequent_itemsets)
		for transaction in transactions:
			for i, itemset in enumerate(candidate_frequent_itemsets):
				if all(_item in transaction for _item in itemset):
					candidate_freq_itemsets_cnts[i] += 1
		level_frequent_itemsets = [itemset for itemset, support in zip(candidate_frequent_itemsets, candidate_freq_itemsets_cnts) if support >= min_support_count]
		frequent_itemsets.extend([set(level_frequent_itemset) for level_frequent_itemset in level_frequent_itemsets])
		candidate_frequent_itemsets = generateCandidateItemsets(level_k, level_frequent_itemsets)

		level_k += 1

	return frequent_itemsets


def __customListsReduce(new_list, reduced_list):
	for item in new_list:
		if item not in reduced_list:
			reduced_list.append(item)
	return reduced_list

	
from os.path import abspath, dirname, join
dataset_filename = './market_basket.csv'

dataset_file = open(dataset_filename)	
n_transactions = 0
for line in dataset_file:
	n_transactions += 1

print("Number of Transactions = {}".format(n_transactions))
min_support = float(input("Please enter the minimum support (as fraction) : "))
comm.bcast(min_support, root=0)

n_trans_root = n_transactions%(comm_size-1)
n_trans_per_worker = n_transactions//(comm_size-1)
dataset_file.seek(0, 0)
for i_process in range(1, comm_size):
	transactions = [set(next(dataset_file).strip().split(',')) for x in range(n_trans_per_worker)]
	comm.send(transactions, dest=i_process, tag=0)
	del transactions
transactions = [set(next(dataset_file).strip().split(',')) for x in range(n_trans_root)]
local_min_support_count = floor(min_support*n_trans_root)
local_frequent_itemsets = aprioriAlgorithm(transactions, local_min_support_count)
candidate_frequent_itemsets = comm.reduce(local_frequent_itemsets, op=__customListsReduce, root=0)

global_min_support_count = floor(min_support*n_transactions)
candidate_freq_itemsets_cnts = [0]*len(candidate_frequent_itemsets)
dataset_file.seek(0, 0)
for transaction_str in dataset_file:
	transaction = set(transaction_str.strip().split(','))
	for i, itemset in enumerate(candidate_frequent_itemsets):
			if itemset <= transaction:
				candidate_freq_itemsets_cnts[i] += 1

global_frequent_itemsets = [itemset for itemset, support in zip(candidate_frequent_itemsets, candidate_freq_itemsets_cnts) if support >= global_min_support_count]

print("\nFREQUENT ITEMSETS")
for frequent_itemset in global_frequent_itemsets:
	print(frequent_itemset)